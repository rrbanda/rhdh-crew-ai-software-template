# Use vLLM (e.g., running Qwen locally)
#LLM_PROVIDER="vllm"
#LLM_BASE_URL="http://localhost:8000"
#LLM_MODEL="/var/home/instruct/.cache/instructlab/models/Qwen/Qwen2.5-Coder-32B-Instruct"
#LLM_API_KEY="apikey"

# Switch to OpenAI
# LLM_PROVIDER="openai"
# LLM_BASE_URL="https://api.openai.com"
# LLM_MODEL="gpt-4o"
# LLM_API_KEY="your-api-key"

# Switch to Granite
 #LLM_PROVIDER="granite"
 #LLM_BASE_URL="https://granite-3-8b-instruct-maas-apicast-production.apps.prod.rhoai.rh-aiservices-bu.com:443"
 #LLM_MODEL="granite-3-8b-instruct"
 #LLM_API_KEY="34c47120741764dcce8636d3f2ba1903"

# Switch to Mistral
LLM_PROVIDER="ollama"
LLM_BASE_URL="http://localhost:11434/"
LLM_MODEL="mistral:latest"
# LLM_API_KEY="your-api-key"
